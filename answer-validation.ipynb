{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fasttext'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24324\\299924797.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mfasttext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAudio\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mWhisperProcessor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mWhisperForConditionalGeneration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'fasttext'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import fasttext, glob\n",
    "import tensorflow as tf\n",
    "from datasets import Dataset, Audio\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "s2t_processor = WhisperProcessor.from_pretrained(\"Subhaka/whisper-small-Sinhala-Fine_Tune\")\n",
    "s2t_model = WhisperForConditionalGeneration.from_pretrained(\"Subhaka/whisper-small-Sinhala-Fine_Tune\")\n",
    "s2t_forced_decoder_ids = s2t_processor.get_decoder_prompt_ids(\n",
    "                                                            language=\"sinhala\", \n",
    "                                                            task=\"transcribe\"\n",
    "                                                            )\n",
    "embedding_model = fasttext.load_model(\"models/cc.si.300.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio(audio_file):\n",
    "\n",
    "    audio_data = Dataset.from_dict(\n",
    "                                    {\"audio\": [audio_file]}\n",
    "                                    ).cast_column(\"audio\", Audio())\n",
    "    audio_data = audio_data.cast_column(\n",
    "                                        \"audio\", \n",
    "                                        Audio(sampling_rate=16000)\n",
    "                                        )\n",
    "    audio_data = audio_data[0]['audio']['array']\n",
    "    return audio_data\n",
    "\n",
    "def transcribe(audio_file):\n",
    "    audio_data = load_audio(audio_file)\n",
    "    input_features = s2t_processor(\n",
    "                                audio_data, \n",
    "                                sampling_rate=16000, \n",
    "                                return_tensors=\"pt\"\n",
    "                                ).input_features\n",
    "    predicted_ids = s2t_model.generate(\n",
    "                                    input_features, \n",
    "                                    forced_decoder_ids=s2t_forced_decoder_ids\n",
    "                                    )\n",
    "    \n",
    "    # transcription = s2t_processor.batch_decode(predicted_ids)\n",
    "    transcription = s2t_processor.batch_decode(\n",
    "                                                predicted_ids, \n",
    "                                                skip_special_tokens=True\n",
    "                                                )\n",
    "    return transcription[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Legion\\.conda\\envs\\tf210\\lib\\site-packages\\transformers\\generation\\utils.py:1346: UserWarning: Using `max_length`'s default (448) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'අක්යෙ කාවෙ'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcription = transcribe('data/pronouncing-evaluation/reference/1.wav')\n",
    "transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(ref_audio_dir='data/answering-evaluation/reference'):\n",
    "    ref_voice_files = glob.glob(f'{ref_audio_dir}/*.wav')\n",
    "    ref_voice_files = [voice_file.replace('\\\\', '/') for voice_file in ref_voice_files]\n",
    "    aut_voice_files = [voice_file.replace('/reference/', '/autism/') for voice_file in ref_voice_files]\n",
    "    non_aut_voice_files = [voice_file.replace('/reference/', '/non-autism/') for voice_file in ref_voice_files]\n",
    "\n",
    "    embeddings_01 = np.zeros((len(ref_voice_files) * 2, 300))\n",
    "    embeddings_02 = np.zeros((len(ref_voice_files) * 2, 300))\n",
    "    labels = np.zeros(len(ref_voice_files) * 2)\n",
    "\n",
    "    errorneous_idxs = []\n",
    "\n",
    "    for idx in range(len(ref_voice_files)):\n",
    "        try:\n",
    "            transcription_01 = transcribe(ref_voice_files[idx])\n",
    "            transcription_02 = transcribe(aut_voice_files[idx])\n",
    "\n",
    "            embeddings_01[idx] = embedding_model.get_sentence_vector(transcription_01)\n",
    "            embeddings_02[idx] = embedding_model.get_sentence_vector(transcription_02)\n",
    "            labels[idx] = 0\n",
    "        except:\n",
    "            errorneous_idxs.append(idx)\n",
    "            print('Errorneous reference file: ', ref_voice_files[idx])\n",
    "            print('Errorneous autism file: ', aut_voice_files[idx])\n",
    "\n",
    "        try:\n",
    "            transcription_01 = transcribe(ref_voice_files[idx])\n",
    "            transcription_02 = transcribe(non_aut_voice_files[idx])    \n",
    "\n",
    "            embeddings_01[idx + len(ref_voice_files)] = embedding_model.get_sentence_vector(transcription_01)\n",
    "            embeddings_02[idx + len(ref_voice_files)] = embedding_model.get_sentence_vector(transcription_02)\n",
    "            labels[idx + len(ref_voice_files)] = 1\n",
    "        except:\n",
    "            errorneous_idxs.append(idx)\n",
    "            print('Errorneous reference file: ', ref_voice_files[idx])\n",
    "            print('Errorneous non-autism file: ', non_aut_voice_files[idx])\n",
    "\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    embeddings_01 = np.delete(embeddings_01, errorneous_idxs, axis=0)\n",
    "    embeddings_02 = np.delete(embeddings_02, errorneous_idxs, axis=0)\n",
    "    labels = np.delete(labels, errorneous_idxs, axis=0)\n",
    "\n",
    "    random_idxs = np.random.permutation(len(labels))\n",
    "    embeddings_01 = embeddings_01[random_idxs]\n",
    "    embeddings_02 = embeddings_02[random_idxs]\n",
    "    labels = labels[random_idxs]\n",
    "    \n",
    "    return embeddings_01, embeddings_02, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding 01 shape:  (14, 300)\n",
      "Embedding 02 shape:  (14, 300)\n",
      "Labels shape:  (14,)\n"
     ]
    }
   ],
   "source": [
    "embeddings_01, embeddings_02, labels = load_dataset()\n",
    "\n",
    "\n",
    "print(\"Embedding 01 shape: \", embeddings_01.shape)\n",
    "print(\"Embedding 02 shape: \", embeddings_02.shape)\n",
    "print(\"Labels shape: \", labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "        inputs01 = tf.keras.Input(shape=(300,))\n",
    "        inputs02 = tf.keras.Input(shape=(300,))\n",
    "\n",
    "        x1 = tf.keras.layers.Dense(300, activation='relu')(inputs01)\n",
    "        x1 = tf.keras.layers.Dropout(0.2)(x1)\n",
    "        x1 = tf.keras.layers.Dense(150, activation='relu')(x1)\n",
    "        x1 = tf.keras.layers.Dropout(0.2)(x1)\n",
    "        x1 = tf.keras.layers.Dense(30, activation='relu')(x1)\n",
    "    \n",
    "        x2 = tf.keras.layers.Dense(300, activation='relu')(inputs02)\n",
    "        x2 = tf.keras.layers.Dropout(0.2)(x2)\n",
    "        x2 = tf.keras.layers.Dense(150, activation='relu')(x2)\n",
    "        x2 = tf.keras.layers.Dropout(0.2)(x2)\n",
    "        x2 = tf.keras.layers.Dense(30, activation='relu')(x2)\n",
    "    \n",
    "        x = tf.keras.layers.concatenate([x1, x2])\n",
    "        x = tf.keras.layers.Dense(30, activation='relu')(x)\n",
    "        x = tf.keras.layers.Dropout(0.2)(x)\n",
    "        outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "        model = tf.keras.Model(\n",
    "                                inputs=[inputs01, inputs02], \n",
    "                                outputs=outputs\n",
    "                                )\n",
    "    \n",
    "        model.compile(\n",
    "                        optimizer='adam',\n",
    "                        loss='binary_crossentropy',\n",
    "                        metrics=[\n",
    "                                tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "                                tf.keras.metrics.Precision(name='precision'),\n",
    "                                tf.keras.metrics.Recall(name='recall'),\n",
    "                                tf.keras.metrics.AUC(name='auc')\n",
    "                                ]\n",
    "                        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 300)]        0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 300)]        0           []                               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 300)          90300       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 300)          90300       ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 300)          0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 300)          0           ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 150)          45150       ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 150)          45150       ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 150)          0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 150)          0           ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 30)           4530        ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 30)           4530        ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 60)           0           ['dense_2[0][0]',                \n",
      "                                                                  'dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 30)           1830        ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 30)           0           ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 1)            31          ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 281,821\n",
      "Trainable params: 281,821\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 3s 14ms/step - loss: 0.7023 - accuracy: 0.3571 - precision: 0.3750 - recall: 0.4286 - auc: 0.3061   \n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.6784 - accuracy: 0.7857 - precision: 0.7500 - recall: 0.8571 - auc: 0.7755\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.6562 - accuracy: 0.9286 - precision: 1.0000 - recall: 0.8571 - auc: 1.0000      \n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.6267 - accuracy: 0.9286 - precision: 1.0000 - recall: 0.8571 - auc: 1.0000      \n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.5835 - accuracy: 0.8571 - precision: 0.7778 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.5075 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.4127 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000      \n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.3022 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.1471 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000      \n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0816 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0596 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0153 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0121 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0083 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0040 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0107 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0183 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0038 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000          \n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0027 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0012 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0022 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0021 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0013 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000  \n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 2.3933e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 1.8219e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0027 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 4.7300e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0012 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000          \n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0012 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000      \n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 6.8936e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 4.4217e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 8.9909e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 4.8616e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0017 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 3.6897e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 1.9219e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0113 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 3.5087e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000      \n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 9.2112e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0032 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 2.5937e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000      \n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 3.7459e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2098985e7f0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "        [embeddings_01, embeddings_02],\n",
    "        labels,\n",
    "        epochs=100,\n",
    "        batch_size=2,\n",
    "        callbacks=[\n",
    "            tf.keras.callbacks.EarlyStopping(\n",
    "                                            monitor='loss',\n",
    "                                            patience=10,\n",
    "                                            restore_best_weights=True\n",
    "                                            )\n",
    "            ]   \n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models/answering-evaluation.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_pronounce_validation(\n",
    "                                    audio_file01,\n",
    "                                    audio_file02\n",
    "                                    ):\n",
    "    transcription_01 = transcribe(audio_file01)\n",
    "    transcription_02 = transcribe(audio_file02)\n",
    "\n",
    "    embedding01 = embedding_model.get_sentence_vector(transcription_01)\n",
    "    embedding02 = embedding_model.get_sentence_vector(transcription_02)\n",
    "\n",
    "    embedding01 = np.expand_dims(embedding01, axis=0)\n",
    "    embedding02 = np.expand_dims(embedding02, axis=0)\n",
    "\n",
    "    prediction = model.predict([embedding01, embedding02])\n",
    "    prediction = prediction.squeeze()\n",
    "\n",
    "    print(prediction)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Legion\\.conda\\envs\\tf210\\lib\\site-packages\\transformers\\generation\\utils.py:1346: UserWarning: Using `max_length`'s default (448) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 150ms/step\n",
      "0.99976903\n"
     ]
    }
   ],
   "source": [
    "response = inference_pronounce_validation(\n",
    "                                        'data/answering-evaluation/reference/Answer2.wav',\n",
    "                                        'data/answering-evaluation/non-autism/Answer2.wav'\n",
    "                                        )\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf210",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
